{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ТИТАНИК\n",
    "======\n",
    "Имеются данные о пассажирах Титаника. \n",
    "\n",
    "В результате работы необходимо построить классификатор, который по данным о пассажире будет предсказывать исход: выжил пассажир или нет.\n",
    "\n",
    "## Часть 1. Работа с признаками.\n",
    "\n",
    "Мы познакомимся с первичной обработкой данных, выявлением признаков для классификации, а также построим модели при помощи разных алгоритмов классификации и сравним результаты.\n",
    "\n",
    "Для дальнейшей работы с данными подключим необходимые библиотеки:\n",
    "- pandas - анализ данных\n",
    "- numpy - работа с массивами\n",
    "- pyplot - отображение данных\n",
    "- seaborn - отображение данных 2\n",
    "- re - регулярные выражения\n",
    "- sklearn - классификаторы/кросс-валидатор/нормализатор/оценка признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.cross_validation import StratifiedKFold, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее необходимо загрузить в память имеющиеся данные: обучающую выборку (training set) и тестовую. Эти процедуры производятся при помощи библиотеки pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Определите обеих размер выборок, например, при помощи встроенной функции len."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задолго до того, как мы приступим к построению моделей, необходимо сделать предварительный анализ данных. Да и вообще, понять с чем придется работать.\n",
    "\n",
    "Для этого нужно \"посмотреть\" на данные и сделать некоторые выводы. Чтобы вывести данные в корректной табличной форме в библиотеке pandas есть метод head(n), который выводит первые n строк данных.\n",
    "\n",
    "**Задание.** Посмотрите на первые строки выборки train_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируем поля данных. У нас есть:\n",
    "- survival - \tПассажир выжил\t0 = нет, 1 = да\n",
    "- pclass - Класс билета(каюты)\t1 = 1ый, 2 = 2ой, 3 = 3ий\n",
    "- sex - Пол\t\n",
    "- Age - Возраст (полных лет)\t\n",
    "- sibsp\t- братьев/сестер/супругов на борту\t\n",
    "- parch\t- родителей/детей на борту\t\n",
    "- ticket - номер билета\t\n",
    "- fare\t- тариф\t\n",
    "- cabin\t- номер каюты\t\n",
    "- embarked - порт посадки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Посмотрите внимательно на данные и попробуйте ответить на вопрос какие закономерности, или наоборот аномалии вы в них наблюдаете (5-7 мин). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжим первичный анализ данных: полезно вычислить средние значения, знать минимальные и максимальные значения по каждому полю. \n",
    "Для того, чтобы вычислять эти характеристики, хорошо было бы иметь как можно больше данных. Можно заметить, что тренировочная и тестовая выборки имеют одну и ту же структуру. Поэтому, есть смысл их объединить в один большой массив данных и анализировать его. Так мы получим более точные средние значения, минимумы, максимумы и т.п.\n",
    "\n",
    "Для того, чтобы объединить выборки в один массив можно использовать функцию из библиотеки panda concat.\n",
    "\n",
    "**Задание.** Назовите новый массив all_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для вычисления средних значений, значений минимумов и максимумов, а также среднеквадратических отклонений и квантилей, удобно использовать функцию descibe. \n",
    "\n",
    "**Задание.** Примените её к созданному массиву all_data и проанализируйте результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом этапе уже можно сделать некоторые предположения о выживаемости, исходя из здравого смысла.\n",
    "\n",
    "Скорее всего выживаемость пассажиров зависит в первую очередь от класса. То есть, \"богатые\" имели больше шансов выжить, чем \"бедные\", которые были расселены по каютам внизу корабля.\n",
    "Кроме того, из истории происшествия известен факт, что при эвакуации старались спасать в большей степени женщин и детей.\n",
    "\n",
    "Рассмотрим связь выживаемости и сочетания класса каюты + пол. Сделаем это при помощи метода библиотеки pandas groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data.groupby([\"Pclass\", \"Sex\"])[\"Survived\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Какие выводы можно сделать исходя из полученных данных?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее при помощи уже известного метода describe можно оценить числовые характеристики данных отдельно для мужчин и для женщин.\n",
    "Но есть смысл рассматривать не все поля, а числовые и, вообще, имеющие для нас какой-то здравый смысл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "describe_fields = [\"Age\", \"Fare\", \"Pclass\", \"SibSp\", \"Parch\"]\n",
    "\n",
    "print(\"Мужчины\")\n",
    "print(train_data[train_data[\"Sex\"] == \"male\"][describe_fields].describe(percentiles=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Выведите аналогичные данные для женщин."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда первичный анализ данных проведен, можно подготавливать признаки для классификации.\n",
    "\n",
    "Как мы заметили выше, у пассажиров могут быть заполнены не все поля. Оставлять в поле значение NaN нельзя, поэтому делаем важный шаг: \n",
    "** Вместо отсутствующих значений подставляем значение медианы, вычисленное по всему столбцу **\n",
    "(Почему именно медиана, а не, к примеру, среднее арифметическое?).\n",
    "\n",
    "Таким образом, мы \"соберем\" медианы по возрасту (ages) в специально созданный экземпаляр класса DataDigest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataDigest:\n",
    "    def __init__(self):\n",
    "        self.ages = None\n",
    "        self.fares = None\n",
    "        self.titles = None\n",
    "        self.cabins = None\n",
    "        self.families = None\n",
    "        self.tickets = None\n",
    "        \n",
    "data_digest = DataDigest()\n",
    "data_digest.ages = train_data.groupby(\"Sex\")[\"Age\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Заполните поле fares аналогично тому как это сделано с полем ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, попытаемся собрать новые признаки. Стратегия такая: лучше сделаем побольше признаков, а потом выясним какие соледует использовать. \n",
    "\n",
    "Какие признаки можно собрать ещё? Например, \"вытащить\" из поля с именем титулы (titles): мистер, мисс, миссис и т.д. В них содержится не только информация о половой принадлежности, но и о возрастной.\n",
    "\n",
    "Можно собрать идентификаторы семей: фамилия + количество человек с такой фамилией на борту (families). \n",
    "\n",
    "Также, сделаем отдельные поля-признаки для кают (cabins) и билетов (tickets).\n",
    "\n",
    "** Замечание! **\n",
    "\n",
    "Обязательно нужно все текстовые поля перевести в числовой формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    # извлекает титул из имени если он указан в его начале\n",
    "    if pd.isnull(name):\n",
    "        return \"Null\"\n",
    "\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1).lower()\n",
    "    else:\n",
    "        return \"None\"\n",
    "\n",
    "def get_family(row):\n",
    "    # определяет принадлежность семье и ее размер\n",
    "    last_name = row[\"Name\"].split(\",\")[0]\n",
    "    if last_name:\n",
    "        family_size = 1 + row[\"Parch\"] + row[\"SibSp\"]\n",
    "        if family_size > 3:\n",
    "            return \"{0}_{1}\".format(last_name.lower(), family_size)\n",
    "        else:\n",
    "            return \"nofamily\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# применим функцию get_title к ячейкам в поле Name, полученный список титулов сохраним\n",
    "data_digest.titles = pd.Index(train_data[\"Name\"].apply(get_title).unique())\n",
    "# применим функцию get_family к строкам датафрейма, полученный список семей сохраним\n",
    "data_digest.families = pd.Index(train_data.apply(get_family, axis=1).unique())\n",
    "# все различные значения кабин тоже сохраним\n",
    "data_digest.cabins = pd.Index(train_data[\"Cabin\"].fillna(\"unknown\").unique())\n",
    "# все различные значения билетов тоже сохраним\n",
    "data_digest.tickets = pd.Index(train_data[\"Ticket\"].fillna(\"unknown\").unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Выведите тип данных поля data_digest.titles и сами значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс pandas.indexes.base.Index (или посто Index) позволяет получать по значению его позицию в списке с помощью функции get_loc. Возможность получать по значению его позицию может быть реализована и другими способами, например, функция index у обычного list.\n",
    "\n",
    "Далее мы создадим сразу много числовых признаков (feature engineering) и разберем как у нас это получилось. Новые признаки:\n",
    "- индекс каюты\n",
    "- индекс палубы (вырезаны из исходных данных по каютам)\n",
    "- индекс билета\n",
    "- индекс титула (вырезаем из имени)\n",
    "- индекс идентификатора семьи (фамилия + братья/сестры + родители/дети)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_index(item, index):\n",
    "    if pd.isnull(item):\n",
    "        return -1\n",
    "\n",
    "    try:\n",
    "        return index.get_loc(item)\n",
    "    except KeyError:\n",
    "        return -1\n",
    "\n",
    "\n",
    "def munge_data(data, digest):\n",
    "    # Age - замена пропусков на медиану в зависимости от пола\n",
    "    data[\"AgeF\"] = data.apply(lambda r: digest.ages[r[\"Sex\"]] if pd.isnull(r[\"Age\"]) else r[\"Age\"], axis=1)\n",
    "\n",
    "    # Fare - замена пропусков на медиану в зависимости от класса\n",
    "    data[\"FareF\"] = data.apply(lambda r: digest.fares[r[\"Pclass\"]] if pd.isnull(r[\"Fare\"]) else r[\"Fare\"], axis=1)\n",
    "\n",
    "    # Gender - замена\n",
    "    genders = {\"male\": 1, \"female\": 0}\n",
    "    data[\"SexF\"] = data[\"Sex\"].apply(lambda s: genders.get(s))\n",
    "\n",
    "    # Gender - расширение\n",
    "    gender_dummies = pd.get_dummies(data[\"Sex\"], prefix=\"SexD\", dummy_na=False)\n",
    "    data = pd.concat([data, gender_dummies], axis=1)\n",
    "\n",
    "    # Embarkment - замена\n",
    "    embarkments = {\"U\": 0, \"S\": 1, \"C\": 2, \"Q\": 3}\n",
    "    data[\"EmbarkedF\"] = data[\"Embarked\"].fillna(\"U\").apply(lambda e: embarkments.get(e))\n",
    "\n",
    "    # Embarkment - расширение\n",
    "    embarkment_dummies = pd.get_dummies(data[\"Embarked\"], prefix=\"EmbarkedD\", dummy_na=False)\n",
    "    data = pd.concat([data, embarkment_dummies], axis=1)\n",
    "\n",
    "    # Количество родственников на борту\n",
    "    data[\"RelativesF\"] = data[\"Parch\"] + data[\"SibSp\"]\n",
    "\n",
    "    # Человек-одиночка?\n",
    "    data[\"SingleF\"] = data[\"RelativesF\"].apply(lambda r: 1 if r == 0 else 0)\n",
    "\n",
    "    # Deck - замена\n",
    "    decks = {\"U\": 0, \"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"T\": 8}\n",
    "    data[\"DeckF\"] = data[\"Cabin\"].fillna(\"U\").apply(lambda c: decks.get(c[0], -1))\n",
    "\n",
    "    # Deck - расширение\n",
    "    deck_dummies = pd.get_dummies(data[\"Cabin\"].fillna(\"U\").apply(lambda c: c[0]), prefix=\"DeckD\", dummy_na=False)\n",
    "    data = pd.concat([data, deck_dummies], axis=1)\n",
    "\n",
    "    # Titles - расширение\n",
    "    title_dummies = pd.get_dummies(data[\"Name\"].apply(lambda n: get_title(n)), prefix=\"TitleD\", dummy_na=False)\n",
    "    data = pd.concat([data, title_dummies], axis=1)\n",
    "\n",
    "    # замена текстов на индекс из соответствующего справочника или -1 если значения в справочнике нет (расширять не будем)\n",
    "    data[\"CabinF\"] = data[\"Cabin\"].fillna(\"unknown\").apply(lambda c: get_index(c, digest.cabins))\n",
    "\n",
    "    data[\"TitleF\"] = data[\"Name\"].apply(lambda n: get_index(get_title(n), digest.titles))\n",
    "\n",
    "    data[\"TicketF\"] = data[\"Ticket\"].apply(lambda t: get_index(t, digest.tickets))\n",
    "\n",
    "    data[\"FamilyF\"] = data.apply(lambda r: get_index(get_family(r), digest.families), axis=1)\n",
    "\n",
    "    # для статистики\n",
    "    age_bins = [0, 5, 10, 15, 20, 25, 30, 40, 50, 60, 70, 80, 90]\n",
    "    data[\"AgeR\"] = pd.cut(data[\"Age\"].fillna(-1), bins=age_bins).astype(object)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cобираем новый набор данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_munged = munge_data(train_data, data_digest)\n",
    "test_data_munged = munge_data(test_data, data_digest)\n",
    "all_data_munged = pd.concat([train_data_munged, test_data_munged])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Классификация.\n",
    "\n",
    "Для решения этой задачи мы будем использовать несколько разных классификаторов и оценим насколько качественные результаты они покажут.\n",
    "Так как разные алгоритмы работают с разными форматами данных, все данные необходимо **нормализовать**.\n",
    "Массив всех известных нам признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\"Pclass\",\n",
    "              \"AgeF\",\n",
    "              \"TitleF\",\n",
    "              \"TitleD_mr\", \"TitleD_mrs\", \"TitleD_miss\", \"TitleD_master\", \"TitleD_ms\", \n",
    "              \"TitleD_col\", \"TitleD_rev\", \"TitleD_dr\",\n",
    "              \"CabinF\",\n",
    "              \"DeckF\",\n",
    "              \"DeckD_U\", \"DeckD_A\", \"DeckD_B\", \"DeckD_C\", \"DeckD_D\", \"DeckD_E\", \"DeckD_F\", \"DeckD_G\",\n",
    "              \"FamilyF\",\n",
    "              \"TicketF\",\n",
    "              \"SexF\",\n",
    "              \"SexD_male\", \"SexD_female\",\n",
    "              \"EmbarkedF\",\n",
    "              \"EmbarkedD_S\", \"EmbarkedD_C\", \"EmbarkedD_Q\",\n",
    "              \"FareF\",\n",
    "              \"SibSp\", \"Parch\",\n",
    "              \"RelativesF\",\n",
    "              \"SingleF\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для нормализации будем использовать стандартный нормализатор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(all_data_munged[features])\n",
    "\n",
    "train_data_scaled = scaler.transform(train_data_munged[features])\n",
    "test_data_scaled = scaler.transform(test_data_munged[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Найдите в Интернете информацию о StandardScaler. Ответьте на два вопроса:\n",
    "- Какое преобразование над данными выполняет StandardScaler?\n",
    "- Почему мы создаем только один экземпляр этого класса?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы заметили ранее, выживаемость зависит от класса+возраста+пола. \n",
    "Мы можем проиллюстрировать это на графиках:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(train_data_munged, vars=[\"AgeF\", \"Pclass\", \"SexF\"], hue=\"Survived\", dropna=True)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Проинтерпретируйте информацию на графиках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Попробуйте при помощи методов groupby (как это было проделано ранее) вывести информацию о выживаемости пассажиров:\n",
    "- относительно возраста\n",
    "- относительно возраста + пола\n",
    "- относительно класса + возраста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При подготовке признаков мы, очевидно, сделали много лишних и малоинформативных.\n",
    "Например, вряд ли порт посадки вносит хоть какой-то вклад в возможность выживания. Некоторые признаки дублируют друг друга (обе колонки, связанные с полом), а некоторые имеют сильную корреляцию (класс билета и стоимость билета).\n",
    "\n",
    "Встроенными возможностями библиотеки scikit-learn можно оценить \"важность\" признаков. Проанализировав результаты, выбросим маловлияющие признаки и оставим для рассмотрения только самые ценные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(train_data_munged[features], train_data_munged[\"Survived\"])\n",
    "\n",
    "valuabilities = -np.log10(selector.pvalues_)\n",
    "\n",
    "plt.bar(range(len(features)), valuabilities)\n",
    "plt.xticks(range(len(features)), features, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В принципе, наши предположения подтвердились: очень важен пол, важен титул (но у него сильная корреляция с полом), весьма важен класс, и, почему-то, палуба F (видимо, дело в её расположении на корабле).\n",
    "\n",
    "Теперь проделаем уже знакомые действия, собирая нормализованную выборку, но которая будет содержать только выбранные нами признаки.\n",
    "\n",
    "**Задание.** В дальнейшем можно поэскпериментировать с набором признаков и посмотреть как будут меняться результаты классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [\"Pclass\",\n",
    "              \"AgeF\",\n",
    "              \"TitleF\",\n",
    "              \"TitleD_mr\", \"TitleD_mrs\", \"TitleD_miss\", \"TitleD_master\", \"TitleD_ms\", \n",
    "              \"TitleD_rev\", \"TitleD_dr\",\n",
    "              \"DeckF\",\n",
    "              \"DeckD_U\", \"DeckD_A\", \"DeckD_C\", \"DeckD_D\", \"DeckD_E\", \"DeckD_F\", \"DeckD_G\",\n",
    "              \"TicketF\",\n",
    "              \"SexF\",\n",
    "              \"SexD_male\", \"SexD_female\",\n",
    "              \"EmbarkedF\",\n",
    "              \"EmbarkedD_S\", \"EmbarkedD_C\", \"EmbarkedD_Q\",\n",
    "              \"SibSp\", \"Parch\",\n",
    "              \"SingleF\"]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_data_munged[features])\n",
    "\n",
    "train_data_scaled = scaler.transform(train_data_munged[features])\n",
    "test_data_scaled = scaler.transform(test_data_munged[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем перейти к классификации полезно разобраться с подходом называемым **кросс-валидация**. Его идея заключается в том, что мы делим тренировочную выборку на n частей, где все части кроме одной будут выступать в качестве тренировчной выборки, а оставшаяся - тестовой. Таким образом, алгоритм n раз \"прогоняется\" на тренировочных выборках, предсказывает на тестовых, и мы получаем значения accuracy - точности (отношение правильных оценок к общему числу). \n",
    "\n",
    "Прежде чем приступить к построению прогностической модели, разобьем выборку на 3 части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(train_data[\"Survived\"], n_folds=3, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание.** Ответьте на вопрос: что делает класс StratifiedKFold?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МЕТОД k БЛИЖАЙШИХ СОСЕДЕЙ (kNN)\n",
    "====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg_ngbh = KNeighborsClassifier(n_neighbors=3)\n",
    "scores = cross_val_score(alg_ngbh, train_data_scaled, train_data_munged[\"Survived\"], cv=cv, n_jobs=-1)\n",
    "print(\"All scores: {}\".format(scores))\n",
    "print(\"Accuracy: {} \\nDisp: {}\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэкспериментируйте со значением k. Что можно сказать по поводу полученных результатов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ГРАДИЕНТНЫЙ СПУСК (Gradient descend)\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МЕТОД ОПОРНЫХ ВЕКТОРОВ (Support vector machine)\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "НАИВНЫЙ БАЙЕСОВСКИЙ КЛАССИФИКАТОР (Naive Bayes classifier)\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЛИНЕЙНАЯ РЕГРЕССИЯ (Linear regression)\n",
    "===\n",
    "\n",
    "Для линейной регрессии (поскольку она регрессия), нужно некоторое рубежное значение, которое позволит нам бинаризовать результат: 1 - выжил, 0 - умер.\n",
    "\n",
    "** Замечание **\n",
    "\n",
    "В предыдущих алгоритмах и далее n_jobs - параметр, который указывает число процессоров, которые будут задействованы в вычислениях.\n",
    "Далее рекомендуется указывать значение n_jobs = 1 (вычислять на одном процессоре), т.к., почему-то, на некоторых компьютерах в иных случаях ноутбук зависает и отказывается считать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_scorer(estimator, x, y):\n",
    "    scorer_predictions = estimator.predict(x)\n",
    "\n",
    "    scorer_predictions[scorer_predictions > 0.5] = 1\n",
    "    scorer_predictions[scorer_predictions <= 0.5] = 0\n",
    "\n",
    "    return metrics.accuracy_score(y, scorer_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg_lnr = LinearRegression()\n",
    "scores = cross_val_score(alg_lnr, train_data_scaled, train_data_munged[\"Survived\"], cv=cv, n_jobs=1,\n",
    "                         scoring=linear_scorer)\n",
    "print(\"Accuracy: {} \\nDisp: {}\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ (Logistic regression)\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Место для вашего кода"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "СЛУЧАЙНЫЙ ЛЕС (Random forest)\n",
    "===\n",
    "\n",
    "Результат работы алгоритма случайного леса будет зависеть от входных параметров. Попытайтесь подобрать наиболее оптимальные с помощью grid_search. Эта функция позволяет перебрать декартово произведение множеств значений нескольких параметров (это называется grid) и для каждого варианта (ячейки в grid) вызвать функцию с этими параметрами.\n",
    "\n",
    "**Комментарий.** Опытным путём установлено, что случайный лес даёт наилучшие результаты без переобучения среди приведенных алгоритмов при хорошо подобранных параметрах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Место для вашего кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
